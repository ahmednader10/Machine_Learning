{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def randPair(s,e):\n",
    "    return np.random.randint(s,e), np.random.randint(s,e)\n",
    "\n",
    "#finds an array in the \"depth\" dimension of the grid\n",
    "def findLoc(state, obj):\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            if (state[i,j] == obj).all():\n",
    "                return i,j\n",
    "\n",
    "#Initialize stationary grid, all items are placed deterministically\n",
    "def initGrid():\n",
    "    state = np.zeros((4,4,5))\n",
    "    #place player 1\n",
    "    state[0,1] = np.array([0,0,0,1,0])\n",
    "    #place wall\n",
    "    state[2,2] = np.array([0,0,1,0,0])\n",
    "    #place pit\n",
    "    state[1,1] = np.array([0,1,0,0,0])\n",
    "    #place goal\n",
    "    state[3,3] = np.array([1,0,0,0,0])\n",
    "    \n",
    "    #place player 2\n",
    "    state[randPair(0,4)] = np.array([0,0,0,0,1])\n",
    "    a1 = findLoc(state, np.array([0,0,0,1,0])) #find grid position of player1 (agent)\n",
    "    a2 = findLoc(state, np.array([0,0,0,0,1])) #find grid position of player2 \n",
    "    w = findLoc(state, np.array([0,0,1,0,0])) #find wall\n",
    "    g = findLoc(state, np.array([1,0,0,0,0])) #find goal\n",
    "    p = findLoc(state, np.array([0,1,0,0,0])) #find pit\n",
    "    if (not a1 or not a2 or not w or not g or not p):\n",
    "        #print('Invalid grid. Rebuilding..')\n",
    "        return initGrid()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMove(state, action,player2_terminated):\n",
    "    #need to locate player in grid\n",
    "    #need to determine what object (if any) is in the new grid spot the player is moving to\n",
    "    player1_loc = getLoc(state, 3)\n",
    "    if not player2_terminated:\n",
    "        player2_loc = getLoc(state, 4)\n",
    "    wall = findLoc(state, np.array([0,0,1,0,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0,0]))\n",
    "    state = np.zeros((4,4,5))\n",
    "\n",
    "    #print player1_loc\n",
    "    #print player2_loc\n",
    "    #up (row - 1)\n",
    "    if action==0:\n",
    "        new_loc = (player1_loc[0] - 1, player1_loc[1])\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "    #down (row + 1)\n",
    "    elif action==1:\n",
    "        new_loc = (player1_loc[0] + 1, player1_loc[1])\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "    #left (column - 1)\n",
    "    elif action==2:\n",
    "        new_loc = (player1_loc[0], player1_loc[1] - 1)\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "    #right (column + 1)\n",
    "    elif action==3:\n",
    "        new_loc = (player1_loc[0], player1_loc[1] + 1)\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "\n",
    "    new_player1_loc = getLoc(state, 3)\n",
    "    #print new_player1_loc\n",
    "    if (not new_player1_loc):\n",
    "        state[player1_loc] = np.array([0,0,0,1,0])\n",
    "    #re-place pit\n",
    "    state[pit][1] = 1\n",
    "    #re-place wall\n",
    "    state[wall][2] = 1\n",
    "    #re-place goal\n",
    "    state[goal][0] = 1\n",
    "    if not player2_terminated:\n",
    "        #re-place player 2\n",
    "        state[player2_loc][4] = 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeMovePlayer2(state,player2_terminated):\n",
    "    #need to locate player in grid\n",
    "    #need to determine what object (if any) is in the new grid spot the player is moving to\n",
    "    player1_loc = getLoc(state, 3)\n",
    "    player2_loc = getLoc(state, 4)\n",
    "    wall = findLoc(state, np.array([0,0,1,0,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0,0]))\n",
    "    state = np.zeros((4,4,5))\n",
    "    \n",
    "    #print player2_loc\n",
    "    action = raw_input(\"Enter 0 for up, 1 for down, 2 for left, 3 for right \")\n",
    "\n",
    "    #up (row - 1)\n",
    "    if action==str(0):\n",
    "        new_loc = (player2_loc[0] - 1, player2_loc[1])\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                if new_loc != goal and new_loc != pit:\n",
    "                    state[new_loc][4] = 1\n",
    "                elif new_loc == goal:\n",
    "                    state[new_loc] = np.array([1,0,0,0,1])\n",
    "                elif new_loc == pit:\n",
    "                        state[new_loc] = np.array([0,1,0,0,1])\n",
    "    #down (row + 1)\n",
    "    elif action==str(1):\n",
    "        new_loc = (player2_loc[0] + 1, player2_loc[1])\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                if new_loc != goal and new_loc != pit:\n",
    "                    state[new_loc][4] = 1\n",
    "                elif new_loc == goal:\n",
    "                    state[new_loc] = np.array([1,0,0,0,1])\n",
    "                elif new_loc == pit:\n",
    "                            state[new_loc] = np.array([0,1,0,0,1])\n",
    "    #left (column - 1)\n",
    "    elif action==str(2):\n",
    "        new_loc = (player2_loc[0], player2_loc[1] - 1)\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                if new_loc != goal and new_loc != pit:\n",
    "                    state[new_loc][4] = 1\n",
    "                elif new_loc == goal:\n",
    "                    state[new_loc] = np.array([1,0,0,0,1])\n",
    "                elif new_loc == pit:\n",
    "                            state[new_loc] = np.array([0,1,0,0,1])\n",
    "    #right (column + 1)\n",
    "    elif action==str(3):\n",
    "        new_loc = (player2_loc[0], player2_loc[1] + 1)\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                if new_loc != goal and new_loc != pit:\n",
    "                    state[new_loc][4] = 1\n",
    "                elif new_loc == goal:\n",
    "                    state[new_loc] = np.array([1,0,0,0,1])\n",
    "                elif new_loc == pit:\n",
    "                            state[new_loc] = np.array([0,1,0,0,1])\n",
    "\n",
    "    new_player2_loc = getLoc(state, 4)\n",
    "    if (not new_player2_loc):\n",
    "        state[player2_loc] = np.array([0,0,0,0,1])\n",
    "    #re-place pit\n",
    "    state[pit][1] = 1\n",
    "    #re-place wall\n",
    "    state[wall][2] = 1\n",
    "    #re-place goal\n",
    "    state[goal][0] = 1\n",
    "     #re-place player 1\n",
    "    state[player1_loc][3] = 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLoc(state, level):\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            if (state[i,j][level] == 1):\n",
    "                return i,j\n",
    "\n",
    "def getReward(state):\n",
    "    player_loc = getLoc(state, 3)\n",
    "    pit = getLoc(state, 1)\n",
    "    goal = getLoc(state, 0)\n",
    "    if (player_loc == pit):\n",
    "        return -10\n",
    "    elif (player_loc == goal):\n",
    "        return 10\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def getRewardPlayer2(state):\n",
    "    player2_loc = getLoc(state, 4)\n",
    "    pit = getLoc(state, 1)\n",
    "    goal = getLoc(state, 0)\n",
    "    if (player2_loc == pit):\n",
    "        return -10\n",
    "    elif (player2_loc == goal):\n",
    "        return 10\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def dispGrid(state,player2_terminated):\n",
    "    grid = np.zeros((4,4), dtype='<U2')\n",
    "    player1_loc = getLoc(state, 3)\n",
    "    player2_loc = getLoc(state, 4)\n",
    "    wall = findLoc(state, np.array([0,0,1,0,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0,0]))\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            grid[i,j] = ' '\n",
    "\n",
    "    if player1_loc:\n",
    "        grid[player1_loc] = 'P1' #player1\n",
    "    if player2_loc:\n",
    "         if not player2_terminated:\n",
    "            grid[player2_loc] = 'P2' #player2\n",
    "    if player1_loc == player2_loc and not player2_terminated:\n",
    "        grid[player1_loc] = 'PB' #player1 and player2\n",
    "    if wall:\n",
    "        grid[wall] = 'W' #wall\n",
    "    if goal:\n",
    "        grid[goal] = '+' #goal\n",
    "    if pit:\n",
    "        grid[pit] = '-' #pit\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[u' ', u'P1', u' ', u' '],\n",
       "       [u' ', u'-', u' ', u' '],\n",
       "       [u' ', u' ', u'W', u' '],\n",
       "       [u' ', u' ', u' ', u'+']], \n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = initGrid()\n",
    "dispGrid(state, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[u' ', u'P1', u' ', u' '],\n",
       "       [u' ', u'-', u' ', u' '],\n",
       "       [u' ', u' ', u'W', u' '],\n",
       "       [u' ', u' ', u' ', u'+']], \n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = makeMove(state, 0,True)\n",
    "print('Reward: %s' % (getReward(state),))\n",
    "dispGrid(state,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import model_from_json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, init='lecun_uniform', input_shape=(80,)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2)) I'm not using dropout, but maybe you wanna give it a try?\n",
    "\n",
    "model.add(Dense(150, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(4, init='lecun_uniform'))\n",
    "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='mse', optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15145586, -0.10695013,  0.02440124, -0.08318168]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(state.reshape(1,80), batch_size=1)\n",
    "#just to show an example output; read outputs left to right: up/down/left/right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 999\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s - loss: 0.3828\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s - loss: 0.0042\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s - loss: 0.0545\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s - loss: 0.0874\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s - loss: 0.0490\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s - loss: 0.0177\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s - loss: 0.0073\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s - loss: 0.0035\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s - loss: 0.0021\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s - loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "epochs = 1000\n",
    "gamma = 0.9 #since it may take several moves to goal, making gamma high\n",
    "epsilon = 1\n",
    "for i in range(epochs):\n",
    "    state = initGrid()\n",
    "    status = 1\n",
    "    #while game still in progress\n",
    "    while(status == 1):\n",
    "        #We are in state S\n",
    "        #Let's run our Q function on S to get Q values for all possible actions\n",
    "        qval = model.predict(state.reshape(1,80), batch_size=1)\n",
    "        if (random.random() < epsilon): #choose random action\n",
    "            action = np.random.randint(0,4)\n",
    "        else: #choose best action from Q(s,a) values\n",
    "            action = (np.argmax(qval))\n",
    "        #Take action, observe new state S'\n",
    "        new_state = makeMove(state, action,False)\n",
    "        #Observe reward\n",
    "        reward = getReward(new_state)\n",
    "        #Get max_Q(S',a)\n",
    "        newQ = model.predict(new_state.reshape(1,80), batch_size=1)\n",
    "        maxQ = np.max(newQ)\n",
    "        y = np.zeros((1,4))\n",
    "        y[:] = qval[:]\n",
    "        if reward == -1: #non-terminal state\n",
    "            update = (reward + (gamma * maxQ))\n",
    "        else: #terminal state\n",
    "            update = reward\n",
    "        y[0][action] = update #target output\n",
    "        print(\"Game #: %s\" % (i,))\n",
    "        model.fit(state.reshape(1,80), y, batch_size=1, nb_epoch=10, verbose=1)\n",
    "        state = new_state\n",
    "        if reward != -1:\n",
    "            status = 0\n",
    "        clear_output(wait=True)\n",
    "    if i== 20 or i == 50 or i == 70 or i == 100 or i == 400 or i == 700 or i == 999:\n",
    "        # serialize model to JSON\n",
    "        file_name = \"model\"+str(i)\n",
    "        model_json = model.to_json()\n",
    "        with open(file_name+\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(file_name+\".h5\")\n",
    "        #print(\"Saved model to disk\")\n",
    "    \n",
    "    if epsilon > 0.1:\n",
    "        epsilon -= (1/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testAlgo(testModel,init=0):\n",
    "    i = 0\n",
    "    state = initGrid()\n",
    "\n",
    "    player2_terminated = False\n",
    "    state1 = state\n",
    "    print(\"Initial State:\")\n",
    "    print(dispGrid(state,player2_terminated))\n",
    "    status = 1\n",
    "    #while game still in progress\n",
    "    while(status == 1):\n",
    "        qval = testModel.predict(state1.reshape(1,80), batch_size=1)\n",
    "        action = (np.argmax(qval)) #take action with highest Q-value\n",
    "        print('Move #: %s; Taking action: %s' % (i, action))\n",
    "        state1 = makeMove(state1, action,player2_terminated)\n",
    "        print(dispGrid(state1,player2_terminated))\n",
    "        reward = getReward(state1)\n",
    "        if reward != -1:\n",
    "            status = 0\n",
    "            print(\"Reward: %s\" % (reward,))\n",
    "            break\n",
    "        if not player2_terminated:\n",
    "            state2 = makeMovePlayer2(state1,player2_terminated)\n",
    "            state1 = state2\n",
    "            if getRewardPlayer2(state1) == -10:\n",
    "                #place pit\n",
    "                state1[1,1] = np.array([0,1,0,0,0])\n",
    "                player2_terminated = True\n",
    "            elif getRewardPlayer2(state1) == 10:\n",
    "                #place goal\n",
    "                state1[3,3] = np.array([1,0,0,0,0])\n",
    "                player2_terminated = True\n",
    "        i += 1 #If we're taking more than 10 actions, just stop, we probably can't win this game\n",
    "        if (i > 10):\n",
    "            print(\"Game lost; too many moves.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testAlgo(model,init=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_after_epochs():\n",
    "    count = [20,50,70,100,400,700,999]\n",
    "    #count = [100]\n",
    "    for i in count:\n",
    "        file_to_load = \"model\"+str(i)\n",
    "        # load json and create model\n",
    "        json_file = open(file_to_load+'.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        testModel = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        testModel.load_weights(file_to_load+\".h5\")\n",
    "        testModel.compile(loss='mse', optimizer=rms)\n",
    "        print(\"Loaded model at epoch \"+str(i)+\" from disk\")\n",
    "        testAlgo(testModel,init=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at epoch 20 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u'P2']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: 3\n",
      "[[u' ' u' ' u'P1' u' ']\n",
      " [u' ' u'-' u' ' u'P2']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 1; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'PB']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 2; Taking action: 3\n",
      "[[u' ' u' ' u'P2' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 3; Taking action: 3\n",
      "[[u' ' u'P2' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 4; Taking action: 3\n",
      "[[u'P2' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 5; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u'P2' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 6; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u'P2' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 3\n",
      "Move #: 7; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u'P2' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 8; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 9; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 10; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Game lost; too many moves.\n",
      "Loaded model at epoch 50 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u'P2' u' ' u'+']]\n",
      "Move #: 0; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u'P2' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 1; Taking action: 0\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u'P2' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 2; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 3; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 4; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 5; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 6; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 7; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 8; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 9; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 10; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Game lost; too many moves.\n",
      "Loaded model at epoch 70 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u'P2' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u'P2' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 1; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u'P1' u'-' u' ' u' ']\n",
      " [u'P2' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 2; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u'P1' u' ' u'W' u' ']\n",
      " [u'P2' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 3\n",
      "Move #: 3; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u'P2' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 4; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u'P2' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 5; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Move #: 6; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Move #: 7; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Move #: 8; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Move #: 9; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Move #: 10; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u'P1' u' ' u' ' u'+']]\n",
      "Game lost; too many moves.\n",
      "Loaded model at epoch 100 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u'P2']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u'P2']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 3\n",
      "Move #: 1; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u'P2']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 2; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u'P2']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 3; Taking action: 3\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P2']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 1\n",
      "Move #: 4; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 5; Taking action: 3\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 6; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 7; Taking action: 3\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 8; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 9; Taking action: 3\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 10; Taking action: 2\n",
      "[[u'P1' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Game lost; too many moves.\n",
      "Loaded model at epoch 400 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P2']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: 3\n",
      "[[u' ' u' ' u'P1' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P2']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 1; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u'P1' u'P2']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 0\n",
      "Move #: 2; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P2']\n",
      " [u' ' u'-' u' ' u'P1']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 3; Taking action: 1\n",
      "[[u' ' u' ' u'P2' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P1']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 4; Taking action: 1\n",
      "[[u' ' u'P2' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'P1']]\n",
      "Reward: 10\n",
      "Loaded model at epoch 700 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u'P2' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: 3\n",
      "[[u' ' u' ' u'P1' u' ']\n",
      " [u' ' u'-' u'P2' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 1; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u'P1' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 2; Taking action: 3\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u'P1']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 3; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P1']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 4; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'P1']]\n",
      "Reward: 10\n",
      "Loaded model at epoch 999 from disk\n",
      "Initial State:\n",
      "[[u' ' u'P1' u' ' u' ']\n",
      " [u' ' u'-' u'P2' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: 3\n",
      "[[u' ' u' ' u'P1' u' ']\n",
      " [u' ' u'-' u'P2' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Enter 0 for up, 1 for down, 2 for left, 3 for right 2\n",
      "Move #: 1; Taking action: 3\n",
      "[[u' ' u' ' u' ' u'P1']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 2; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u'P1']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 3; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P1']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 4; Taking action: 1\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'P1']]\n",
      "Reward: 10\n"
     ]
    }
   ],
   "source": [
    "test_after_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
